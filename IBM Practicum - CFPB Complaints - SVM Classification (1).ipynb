{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Master DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanmcalevey/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "master_df = pd.read_csv('Consumer_Complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Payday loan, title loan, or personal loan</td>\n",
       "      <td>Installment loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company believes it acted appropriately as aut...</td>\n",
       "      <td>Atlas Credit Company, Inc.</td>\n",
       "      <td>TX</td>\n",
       "      <td>75703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3391722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other debt</td>\n",
       "      <td>False statements or representation</td>\n",
       "      <td>Attempted to collect wrong amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ProCollect, Inc</td>\n",
       "      <td>TX</td>\n",
       "      <td>79936</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3391649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Auto debt</td>\n",
       "      <td>Written notification about debt</td>\n",
       "      <td>Notification didn't disclose it was an attempt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAVY FEDERAL CREDIT UNION</td>\n",
       "      <td>CA</td>\n",
       "      <td>91915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3391379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OKLAHOMA STUDENT LOAN AUTHORITY</td>\n",
       "      <td>IN</td>\n",
       "      <td>47130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3391378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Medical debt</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company disputes the facts presented in the co...</td>\n",
       "      <td>Eastern Account Systems of Connecticut, Inc.</td>\n",
       "      <td>CT</td>\n",
       "      <td>06401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/01/2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3391434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    10/01/2019          Payday loan, title loan, or personal loan   \n",
       "1    10/01/2019                                    Debt collection   \n",
       "2    10/01/2019                                    Debt collection   \n",
       "3    10/01/2019  Credit reporting, credit repair services, or o...   \n",
       "4    10/01/2019                                    Debt collection   \n",
       "\n",
       "        Sub-product                                 Issue  \\\n",
       "0  Installment loan           Struggling to pay your loan   \n",
       "1        Other debt    False statements or representation   \n",
       "2         Auto debt       Written notification about debt   \n",
       "3  Credit reporting  Incorrect information on your report   \n",
       "4      Medical debt     Attempts to collect debt not owed   \n",
       "\n",
       "                                           Sub-issue  \\\n",
       "0                                                NaN   \n",
       "1                  Attempted to collect wrong amount   \n",
       "2  Notification didn't disclose it was an attempt...   \n",
       "3                      Account information incorrect   \n",
       "4                                  Debt is not yours   \n",
       "\n",
       "  Consumer complaint narrative  \\\n",
       "0                          NaN   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                          NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0  Company believes it acted appropriately as aut...   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Company disputes the facts presented in the co...   \n",
       "\n",
       "                                        Company State ZIP code           Tags  \\\n",
       "0                    Atlas Credit Company, Inc.    TX    75703            NaN   \n",
       "1                               ProCollect, Inc    TX    79936  Servicemember   \n",
       "2                     NAVY FEDERAL CREDIT UNION    CA    91915            NaN   \n",
       "3               OKLAHOMA STUDENT LOAN AUTHORITY    IN    47130            NaN   \n",
       "4  Eastern Account Systems of Connecticut, Inc.    CT    06401            NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0       Consent not provided           Web           10/01/2019   \n",
       "1       Consent not provided           Web           10/01/2019   \n",
       "2                        NaN           Web           10/01/2019   \n",
       "3                        NaN           Web           10/01/2019   \n",
       "4                      Other           Web           10/01/2019   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                NaN   \n",
       "1      Closed with explanation              Yes                NaN   \n",
       "2                  In progress              Yes                NaN   \n",
       "3      Closed with explanation              Yes                NaN   \n",
       "4      Closed with explanation              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3391722  \n",
       "1       3391649  \n",
       "2       3391379  \n",
       "3       3391378  \n",
       "4       3391434  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: dropping missing narratives, removing 'X's, and taking an even sample of 1,000(/10,000) narratives with timely and un-timely responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df = master_df.dropna(subset=['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proc_df['Rapid response'] = (proc_df['Timely response?'] == 'Yes') & (proc_df['Consumer disputed?'] != 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proc_df['Rapid response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = proc_df[proc_df['Timely response?']=='Yes'].sample(2000)\n",
    "\n",
    "new_df2 = proc_df[proc_df['Timely response?']=='No'].sample(2000)\n",
    "\n",
    "df = new_df.append(new_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clean = [re.sub('X', '', nar) for nar in df['Consumer complaint narrative']]\n",
    "\n",
    "second_clean = [re.sub(\"\\'\", ' ', nar) for nar in first_clean]\n",
    "\n",
    "df['Cleaned narratives'] = [nar for nar in second_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns_adjs(text):\n",
    "    \n",
    "    # So far it seems like the best POS tags are: Nouns, Adjectives, Adverbs, Superlative Adjs\n",
    "    \n",
    "    \"\"\"Noun 'NN', Adjective 'JJ', Adverb 'RB', Superlative Adverb 'RBS', Superlative Adjective 'JJS', \n",
    "    Personal Pronoun 'PRP', Personal Pronoun Possessive 'PRP$' \"\"\"\n",
    "    \n",
    "    noun_adj = lambda pos: (pos[:2] == 'NN' or pos[:2] == 'JJ' or pos[:2] == 'RB' or pos[:2] == 'RBS'\n",
    "                            or pos[:2] == 'JJS')\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adjs = [word for (word, pos) in pos_tag(tokenized) if noun_adj(pos)]\n",
    "    output = ' '.join(nouns_adjs)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned narratives'] = [nouns_adjs(nar) for nar in df['Cleaned narratives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "\n",
    "# df['Subjectivity'] = [TextBlob(blob).subjectivity for blob in df['Cleaned narratives'] ]\n",
    "\n",
    "# df['Polarity'] = [TextBlob(blob).polarity for blob in df['Cleaned narratives']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned narratives'], \n",
    "                                                       df['Timely response?'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#vectorizer = CountVectorizer(stop_words='english', ngram_range=(1,3), min_df=5)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=3)\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# X_train['Cleaned narratives'] = vectorizer.fit_transform(X_train['Cleaned narratives'])\n",
    "\n",
    "# X_test['Cleaned narratives'] = vectorizer.transform(X_test['Cleaned narratives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# n_components = 200\n",
    "\n",
    "# svd = TruncatedSVD(n_components)\n",
    "    \n",
    "# X_train = svd.fit_transform(X_train)\n",
    "\n",
    "# X_test = svd.transform(X_test)\n",
    "    \n",
    "# explained_variance_1 = round(100*sum(svd.explained_variance_ratio_), 3)\n",
    "\n",
    "# print('Retained info after SVD: ' + str(explained_variance_1) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: {'svc__C': 0.55}\n",
      "Train score: 0.8623333333333333\n",
      "Test score: 0.706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_pipe = make_pipeline(SVC(kernel='linear'))\n",
    "\n",
    "param_grid = {'svc__C': [0.4, 0.55, 0.7]}\n",
    "\n",
    "cv_input = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#svc = SVC(kernel='linear', C=1)\n",
    "\n",
    "grid = GridSearchCV(svc_pipe, param_grid, cv=cv_input).fit(X_train, y_train)\n",
    "\n",
    "#svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best param: {grid.best_params_}')\n",
    "\n",
    "print(f'Train score: {grid.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test score: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9976666666666667\n",
      "Test score: 0.685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Train score: {rf_clf.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test score: {rf_clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gradientboostingclassifier__learning_rate': 0.075}\n",
      "Train score: 0.781\n",
      "Test score: 0.671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe = make_pipeline(GradientBoostingClassifier(n_estimators=100))\n",
    "\n",
    "param_grid = {'gradientboostingclassifier__learning_rate': [0.025, 0.05, 0.075]}\n",
    "\n",
    "cv_input = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv_input).fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "\n",
    "print(f'Train score: {grid.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test score: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'bernoullinb__alpha': 0.6}\n",
      "Train score: 0.867\n",
      "Test score: 0.695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipe = make_pipeline(BernoulliNB())\n",
    "\n",
    "param_grid = {'bernoullinb__alpha': [0.6, 0.65, 0.7, 0.75, 0.8, 0.9, 1]}\n",
    "\n",
    "cv_input = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv_input).fit(X_train, y_train)\n",
    "\n",
    "#bernoulli.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "\n",
    "print(f'Train score: {grid.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test score: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'adaboostclassifier__learning_rate': 0.1}\n",
      "Train score: 0.7453333333333333\n",
      "Test score: 0.653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "pipe = make_pipeline(AdaBoostClassifier(n_estimators=200))\n",
    "\n",
    "param_grid = {'adaboostclassifier__learning_rate': [0.1, 0.3, 0.5]}\n",
    "\n",
    "cv_input = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv_input).fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "\n",
    "print(f'Train score: {grid.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test score: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'xgbclassifier__eta': 0.05}\n",
      "Train score: 0.7736666666666666\n",
      "Test score: 0.665\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe = make_pipeline(XGBClassifier())\n",
    "\n",
    "param_grid = {'xgbclassifier__eta': [0.05, 0.075, 0.1]}\n",
    "\n",
    "cv_input = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv_input).fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "\n",
    "print(f'Train score: {grid.score(X_train, y_train)}')\n",
    "\n",
    "print(f'Test score: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'XGBClassifier'\n",
    "\n",
    "outfile = open(filename, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid, outfile)\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
